<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<head>
  <link rel="stylesheet" type="text/css" href="../../../mathBlogStyle.css">

  <script type="text/javascript" src="../../../jquery_3.4.1.js"></script>
  <script type="text/javascript" src="../../../menu.js"></script> 
  <script type="text/javascript" src="../../../mathBlogMain.js"></script> 
  <script type="text/x-mathjax-config">
    configureMathJax();
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>  
</head>

<body>
  <div id="menu"></div>

  <div class="mainText">
    <div class="article">
      <h2 class="title" date=""></h2>

<tt> 12 June 2018</tt>
<br>

<br>
    <i>   We teach students that condition $\det A=\pm 1$ still does not mean that 
 the matrix $A$ is orthogonal. However  if  $\det A=\pm 1$
and all columns of the matrix $A$   have unit length, then this guarantees
that $A$ is orthogonal matrix: this immediately follows
from the fact that  volume of parallelepiped $\Pi$
formed  by columns of matrix  $A$ is less or equal to the product
of its lengths, and it is equal to the product if and only if
all the edges are orthogonal to each other.  
Sure intuitively this works for any dimensions,
and the proof is very simle.
    </i>
<br>
 <br>
<br>
   <b> Theorem</b>
Let $A=||a_{ij}||$, $i,j=1.\dots,n$  
be $n\times n$ matrix with real entries.
  Then
          $$
\left|\det A\right|\leq \,\,
\hbox{product of lengths of all its columns}=
\prod_{j=1}^n\left(\sum_{i=1}^n a_{ij}a_{ij}\right)
\tag{1a}
         $$
and
          $$
\left|\det A\right|=\,\,
\hbox{product of lengths of all its columns}
         $$
     if and only if the columns are orthogonal to each other.
<br>
 <br>
<br>
If we consider  columns of matrix as vectors in $\R^n$, then
the statement of theorem means:
        $$
A=\{\ac_1,\dots,\ac_n\}\,,\,
\left|\det A\right|
\leq \prod_{i=1}^n 
   |\ac_i|\,,
\tag{1a}
        $$ 
and
     $$
\left|\det A\right|=
 \prod_{i=1}^n 
   |\ac_i|\,, \Leftrightarrow \hbox {vectors $\ac_i$ are 
orthogonal to each other}
     $$
In particular we come to the 
<br>
<b> Corollary</b>  Unimodular matrix with
columns of unit length is orthogonal matrix.
<br>
 <br>
<br>
This theorem has clear geometrically meaning,
and it is almost evident for $n\leq 3$:
<br>
{\sl The volume of parallelepiped (the area of parallelogram) 
is less than
equal to the product of its edges, and it is eual to this 
product, if and only if all edges are rothogonal to each other. 
}
<br>
\m
<br>
{\sl Proof}.  For $n=1,n=2$
this is obvious: e.g. for $n=2$ this means that
the area of rombus with unit edges is equal to
one if and only if the edges are orthogonal, i.e. the
rombus is a quadrate.
<br>
Consider linear algebra proof for arbitrary $n$.
  Let $n\times n$ matrix be presented by $n$ vectors
$\ac_1,\dots, \ac_n$ of $\R^n$:
      $$
A=\{\ac_1,\ac_2,\dots,\ac_{n-1},\ac_n\}\,, \ac_i\in \R^n\,.
      $$
<br>
We suppose that these vectors are linearly independent
(In the case if these vectors are linearly dependant then 
$\det A=0$).  Perform Gram-Schmidt procedure:
<br>
Consider the vectors 
$\{\b_1,\b_2,\dots,\b_{n-1},\b_n\}$ such that
           $$
     \matrix
           {
     \b_1=\ac_1\cr
   \b_2=\ac_2+\lambda \ac_1\,,\hbox {such that 
$\b_2$ is orthogonal 
to $\b_1$}\cr
  \b_3=\ac_3+\mu_1 \ac_1+\mu_2\ac_2\,,\hbox 
{such that $\b_3$ is orthogonal 
to vectors $\ac_1$ and $\ac_2$}\cr
  \b_4=\ac_3+\nu_1 \ac_1+\nu_2\ac_2+\nu_3\ac_3\,,\hbox 
{such that $\b_4$ is orthogonal 
to vectors $\ac_1$, $\ac_2$ and $\ac_3$}\cr
   \hbox {and so on}
            }
             $$
We come to the new basis $\{\b_i\}$ in $\R^n$ such that
all $\b_i$ are pariwise orthogonal to each other:
           $$
     (\b_i,\b_j)=0\,,\quad \hbox {if $i\not=j$}\,,
           $$ and
and for every $i$
    $$
\ac_i=\b_i+\sum_{k=1}^{i-1} c^m\b_m\,,\quad
    i=1,2,3,\dots,n\,.
     $$
This in particular implies that 
every vector $\b_i$  has the length less than equal 
to the length
of the vector $\ac_i$.   Moreover  
It is evident that this orthogonalisation does not
change the determinant:
    $$
\det A=\det \{\ac_1,\dots,\ac_n\}=\det \{\b_1,\dots,\b_n\}\,
           $$
Thus we come to
          $$
|\det A|=\sqrt {\det A^+A}=
   \det
      \left(
        \matrix
        {
    |\b_1|^2 &0  & 0 &\dots &  0\cr
       0 &|\b_2|^2  & 0 &\dots &  0\cr
       0 & 0 & |\b_3|^2  &\dots &  0\cr
              \dots \cr
       0 & 0 & 0  &\dots &  |\b_n|^2\cr
        }
       \right)=
            $$
            $$
      =
   \sqrt {|\b_1|^2\cdot\dots \cdot |\b_n|^2}\leq
     |\ac_1|\cdot\dots\cdot |\ac_n|\,.
          $$
The equality implies   that $\ac_i=\b_i$.
<br>
</div>
  </div>
 </body>
</html>